# Реализация системы извлечения изображений по текстовому описанию и поиск похожих фотографий

**Дано:** 
1. `train_dataset.csv` содержит информация, необходимая для обучения: 
2. Папка `train_images` содержит изображения для тренировки модели.
3. `CrowdAnnotations.tsv` содержит данные по соответствию изображения и описания, полученные с помощью краудсорсинга.
4. `ExpertAnnotations.tsv` содержит данные по соответствию изображения и описания, полученные в результате опроса экспертов.
5. `test_queries.csv` содержит информацию, необходимую для тестирования.
6. Папка `test_images` содержит изображения для тестирования модели.

**Цель:** разработка демонстрационной версии поиска изображений по запросу.

## Применяемые библиотеки: 

pandas, numpy, plotly, sklearn, optuna, scipy, torch, torchvision, transformers

## Вывод

## 8. Общие выводы

**Тестирование модели.** Обучение нейросети на полном объёме данных показал схожую метрику RMSE=0.182, полученную на кросвалидации 0.18. Анализируя качество инференса модели приходим к выводу, что модель смогла уловить общие понятия, такие как собака, дети, зима, группа людей и т.д., ровно те объекты, которые часто можно встретить в обучающем наборе данных. Для более тонких понятий как мужчина/женщина или мелких объектов модель непригодна.     Резюмируя вывод, проект по созданию сервиса поиска фотографий по текстовому описанию практически осуществим, для чего потребуется значительно более разнообразный объём данных и вариантов его описания, а так же потребуется увеличить размер векторов для выявления более тонких соответствий.

---
Автор: Евтухов Павел

E-mail: xswepp@tut.by

https://t.me/xswepp
