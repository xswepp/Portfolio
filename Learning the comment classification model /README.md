# Обучение модели классификации комментариев

**Дано:** данные представленны таблицей с разметкой о токсичности правок. Столбец `'text'` в нём содержит текст комментария, а `'toxic'` — целевой признак.

**Цель:** создание системы для определения эмоциональной оценки коментариев.

## Применяемые библиотеки: 

pandas, numpy, seaborn, plotly, sklearn, nltk, optuna, xgboost, catboost

## Вывод

- **Обучение моделей.** Результаты безлайнового тестирования показывает лучшие результаты с предобученной нейросетью `unitary/toxic-bert` на модели XGBClassifier (f1: 0.925). Подбор гиперпараметров улучшил значение целевой метрики до f1: 0.946, немного снизив полноту с 0.973 до 0.954, и заметно повысив точность с 0.882 до 0.938. Хорошие но значительно более слабые результаты показывают подходы с bag-of-words и TF-IDF с LogisticRegression, дающие значения целевой метрики f1: 0.760/0.756, и требующие значительно более качественной подготовки текста, чем нейронная сеть.
- 
- **Тестирование выбранного решения.** В ходе тестирования наиболее удачного подхода классификации текста на позитивные и негативные варианта, получено слабое снижение целевой метрики f1 с 0,946 до 0,937, что значительно выше установленного минимального предела оценки в 0,75. Можно отметить очень высокое значение метрики AUPRC=0.985, а также очень малую долю ошибок классификации негативного класса (0,8%), и низкую ошибку в классификации позитивного класса 5,4%.

---
Автор: Евтухов Павел

E-mail: xswepp@tut.by

https://t.me/xswepp

